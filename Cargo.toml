[package]
name = "word_bounds"
authors = ["orgrinrt", "Hiisi Digital"]
version = "0.0.1"
edition = "2021"
description = """
Word bound detection and string segmentation with flexible rule-based approach and varying implementations to choose 
from
"""
license = "MIT"
license-file = "LICENSE"
readme = "README.md"
keywords = ["string", "word", "bounds", "segmentation", "tokenization"]
categories = ["text-processing", "value-formatting", "development-tools"]
documentation = "https://docs.rs/word_bounds"
homepage = "https://github.com/orgrinrt/word_bounds"
repository = "https://github.com/orgrinrt/word_bounds"

[[bench]]
name = "segmentation"
harness = false

[dev-dependencies]
criterion = { version = "0.5.1" }

[dependencies]
regex = { version = "1.10.5", optional = true }
fancy-regex = { version = "0.13.0", optional = true }
unicode-segmentation = { version = "1.11.0", optional = true }
once_cell = { version = "1.8.0", optional = true }

[features]
default = ["optimize_for_cpu"]
# implementation options
#---- defaults to charwalk if no `use` flags set
use_fancy_regex = ["fancy-regex"]
use_regex = ["regex"]
# performance flags
optimize_for_memory = ["once_cell"]
optimize_for_cpu = ["once_cell"]
enhanced_accuracy = ["unicode-segmentation"] # at cost of performance
# misc
benchmark = ["regex", "fancy-regex", "optimize_for_cpu"]
